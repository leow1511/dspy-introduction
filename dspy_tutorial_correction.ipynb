{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à DSPy\n",
    "Ce notebook va servir d'introduction à DSPy, un package dont le but est d'optimiser les prompts et les poids des llm.\n",
    "Au lieu de se concentrer sur du prompt engineering comme sur langchain, DSPy propose une approche plus classique pour des Data Scientist :\n",
    " - on crée un dataset comprenant des exemples de tâches que l'on souhaite faire au llm (ex: question + réponse attendue),\n",
    " - on \"entraîne\" puis valide notre llm sur des sous-ensembles de notre dataset, comme pour entraîner un modèle classique,\n",
    " - on sauvegarde notre llm, que l'on pourra charger plus tard pour executer un tâche.\n",
    "\n",
    "#### Sur ce, commençons par importer des modules et initialiser quelques variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Après avoir configuré le llm par défaut, il suffit de lui envoyer une chaîne de caractères pour simplement intéragir avec lui :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Le cheval Blanc d'Henri IV est blanc.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo(\"Quelle est la couleur du cheval Blanc d'Henri IV ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSPy possède une première classe essentielle, les Signatures.\n",
    "Les Signatures DSPy sont un moyen de faire comprendre au llm les inputs, outputs et tâches à accomplir avec une écriture très compacte.\n",
    "\n",
    "Une Signature est données par la structure \"input\" -> \"output\" où le nom des variables d'entrée/sortie doivent avoir du sens car seront utilisés par le llm.\n",
    "Par exemple :\n",
    "\n",
    "- Question Answering: \"question -> answer\"\n",
    "\n",
    "- Sentiment Classification: \"sentence -> sentiment\"\n",
    "\n",
    "- Summarization: \"document -> summary\"\n",
    "\n",
    "Essayons par exemple de faire un résumé de texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Summary: Le boson de Higgs, également connu sous le nom de boson BEH, est une particule élémentaire dont l'existence a été postulée par plusieurs scientifiques en 1964. Il permet d'expliquer la brisure de l'interaction unifiée électrofaible et pourquoi certaines particules ont une masse tandis que d'autres n'en ont pas.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte_long = \"\"\"\n",
    "    Le boson de Higgs ou boson BEH, est une particule élémentaire dont l'existence, postulée indépendamment en juin 1964 par François Englert et Robert Brout, par Peter Higgs, en août, \n",
    "    et par Gerald Guralnik, Carl Richard Hagen et Thomas Kibble, permet d'expliquer la brisure de l'interaction unifiée électrofaible (EWSB, pour l'anglais electroweak symmetry breaking)\n",
    "    en deux interactions par l'intermédiaire du mécanisme de Brout-Englert-Higgs-Hagen-Guralnik-Kibble et d'expliquer ainsi pourquoi certaines particules ont une masse et d'autres \n",
    "    n'en ont pas.\"\"\"\n",
    "\n",
    "résumateur = dspy.Predict(\"paragraph -> summary\")\n",
    "résumateur(paragraph=texte_long).summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il suffit de changer le nom de l'output pour changer la fonction du programme. Faire un \"citeur_dinventeur\" qui va donner le nom des inventeurs d'une expérience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inventor Names: François Englert, Robert Brout, Peter Higgs, Gerald Guralnik, Carl Richard Hagen, Thomas Kibble'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citeur_dinventeur = dspy.Predict(\"paragraph -> inventor_names\")\n",
    "citeur_dinventeur(paragraph=texte_long).inventor_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'on a pas besoin de préciser quel llm la signature va utiliser puisqu'il est définit en haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"La couleur du cheval Blanc d'Henri IV est blanc.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexte = \"Henri IV avait un cheval dénommé Blanc qui était en réalité d'un pelage opposé de blanc...\"\n",
    "\n",
    "qa = dspy.Predict(\"context, question -> answer\")\n",
    "qa(context=contexte, question=\"Quelle est la couleur du cheval Blanc d'Henri IV ?\").answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le llm n'a pas compris. Predict est la signature de base mais on peut dire au llm de raisonner en utilisant la signature ChainOfThought.\n",
    "\n",
    "PS : essayez de ne pas regarder que l'attribut \"answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The color of the horse Blanc, owned by Henri IV, is black.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "qa(context=contexte, question=\"Quelle est la couleur du cheval Blanc d'Henri IV ?\").answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on veut ajouter des contraintes pour des tâches plus spécifiques, on peut raffiner une signature ou en créer une nous-même. Par exemple, disons qu'on veut une réponse plus courte et en français :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Noir.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class reponse_concise(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Return the answer to a question using context. Keep the answer short and return it in French.\n",
    "    \"\"\"\n",
    "    context = dspy.InputField()\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Short answer, less then 5 words. Must be in French.\")\n",
    "\n",
    "qa = dspy.ChainOfThought(reponse_concise)\n",
    "qa(context=contexte, question=\"Quelle est la couleur du cheval Blanc d'Henri IV ?\").answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous sommes des pros des signatures, nous pouvons passer aux modules. Si une Signature est comme une couche de réseau de neuronnes, les modules sont comme les modèles complets. On peut y mettre plusieurs signatures qui s'occupent de différentes tâches, par exemple si on veut reprendre notre exemple où l'on veut que notre llm réponde juste \"noir\", on peut le décomposer en un llm qui répond, puis un qui traduit, ce qui donnerait ça :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentence: The color of the horse Blanc, owned by Henri IV, is black.\\nFrench Translation: La couleur du cheval Blanc, appartenant à Henri IV, est noire.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class qa_en_français(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "        self.translate = dspy.Predict(\"sentence -> french_translation\")\n",
    "    \n",
    "    def forward(self, context, question):\n",
    "        eng_answer = self.generate_answer(context=context, question=question)\n",
    "        french_answer = self.translate(sentence=eng_answer.answer)\n",
    "        return french_answer\n",
    "\n",
    "qa = qa_en_français()\n",
    "qa(context=contexte, question=\"Quelle est la couleur du cheval Blanc d'Henri IV ?\").french_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas mal mais il renvoie \"sentence : .... French Translation :\" alors qu'on voudrait juste la réponse.\n",
    "C'est là qu'intervient toute la magie de DSPy : au lieu de perdre du temps à faire du prompt engenireeing sans trop savoir où on va, il nous suffit de produire 3 exemples du comportement qu'on attendrais et d'entraîner notre module sur ces exemples. Commençons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = dspy.Example(context=\"Double-birds are a new species of flying animals with 4 eyes and 3 wings\", question=\"How many wings does a double-bird have ?\", answer=\"Les double-oiseaux ont 3 ailes.\").with_inputs(\"context\", \"question\")\n",
    "\n",
    "ex2 = dspy.Example(context=\"\", question=\"Combien de cm y a-t-il dans 1m\", answer=\"Il y a cent centimètres dans un mètre.\").with_inputs(\"context\", \"question\")\n",
    "\n",
    "ex3 = dspy.Example(context=texte_long, question=\"Quel est l'autre nom du boson de Higgs ?\", answer=\"Le Boson de Higgs est aussi appelé Boson BEH\").with_inputs(\"context\", \"question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut maintenant définir une fonction de coût. Tout est possible tant que ça renvoie un Booléen.\n",
    "On peut checker que la phrase soit exactement comme notre label, on peut check que certains mot-clés soient dans notre réponse (par ex, checker que \"Boson BEH\" apparaisse dans notre réponse à l'exemple 3).\n",
    "\n",
    "Par exemple, si on voulait checker que la réponse soit exactement la même, on pourrait utiliser cette loss :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(example, pred, trace=None):\n",
    "    return example.answer.lower() == pred.french_translation.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, dans notre cas, on s'en fout si on a pas la même phrase au mot près. On veut juste une réponse valide en français. Et comme c'est un peu dur à expliciter et qu'on a de toute façon pas beaucoup d'exemples, on va utiliser une fonction de coût super pratique : nous-même !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_truth(example, pred, trace=None):\n",
    "    print(example[\"question\"])\n",
    "    print(\"\\n\")\n",
    "    print(pred.french_translation)\n",
    "    response = input(\"Is the answer good ? (y/n): \")\n",
    "    return response.lower() == \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant entrainer notre modèle sur ces exemples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many wings does a double-bird have ?\n",
      "\n",
      "\n",
      "Sentence: A double-bird has 3 wings.\n",
      "French Translation: Un oiseau double a 3 ailes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:05<00:10,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combien de cm y a-t-il dans 1m\n",
      "\n",
      "\n",
      "Il y a 100 centimètres dans 1 mètre.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:11<00:05,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quel est l'autre nom du boson de Higgs ?\n",
      "\n",
      "\n",
      "The other name of the Higgs boson is the BEH boson.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:15<00:00,  5.10s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many wings does a double-bird have ?\n",
      "\n",
      "\n",
      "Sentence: A double-bird has 3 wings.\n",
      "French Translation: Un oiseau double a 3 ailes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:04<00:08,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quel est l'autre nom du boson de Higgs ?\n",
      "\n",
      "\n",
      "L'autre nom du boson de Higgs est le boson BEH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.26s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many wings does a double-bird have ?\n",
      "\n",
      "\n",
      "Sentence: A double-bird has 3 wings.\n",
      "French Translation: Un oiseau double a 3 ailes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples in round 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = [ex1, ex2, ex3]\n",
    "metric = check_truth\n",
    "teleprompter = BootstrapFewShot(\n",
    "    metric=metric,\n",
    "    max_rounds=3,\n",
    ")\n",
    "trained_qa = teleprompter.compile(\n",
    "    qa, trainset=trainset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"La couleur du cheval Blanc d'Henri IV est noire.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_qa(context=contexte, question=\"Quelle est la couleur du cheval Blanc d'Henri IV ?\").french_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('DSPY-obavSNUU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "936202ed573e1554d99167fcebaaab31b1d41ef89fa290e355dde88d5319cd47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
